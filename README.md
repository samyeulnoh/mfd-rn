# MFD-RN

This repository provides an original PyTorch implementation of the approach described in our paper, "**Sample-Efficient and Occlusion-Robust Reinforcement Learning for Robotic Manipulation via Multimodal Fusion Dualization and Representation Normalization**."



## Methodology

Our method is an effective reinforcement learning (RL) approach for robotic manipulation that is fully end-to-end trainable, highly sample-efficient, and robust to object occlusions. By effectively integrating vision and proprioception without relying on tactile feedback, our approach addresses critical challenges in robotic manipulation tasks involving occlusions. 

The core innovation of our method is the **multimodal fusion dualization** technique, which separates the fusion process into two distinct modules, each optimized independently for the actor and the critic. This separation provides tailored representations for each network, enhancing actorâ€“critic learning. Additionally, **representation normalization** techniques, including LayerNorm and SimplexNorm, are incorporated into the represenation learning process to improve training stability and prevent issues such as gradient explosion. Together, these contributions significantly boost RL performance and sample efficiency, enabling more effective and robust robotic manipulation in complex, visually obscured environments. 

![architecture](https://dl.dropbox.com/scl/fi/y6zsbbjsgpil5xa1vjsp2/Fig1.png?rlkey=w5r32hnbygyulx6dgphesrw7e&st=5z87vv9t&dl=0)


Our method not only effectively tackles challenging robotic manipulation tasks involving occlusions but also outperforms five state-of-the-art visual RL methods (**DrQ**, **DrQ-v2**, **CURL**, **TACO**, and **DrM**) and two prominent state-based RL methods (**TD3** and **SAC**) in both sample efficiency and task performance. Remarkably, it achieves these results without relying on tactile sensors or requiring prior knowledge such as predefined low-dimensional coordinate states or pre-trained representations. 

![comparison](https://dl.dropbox.com/scl/fi/s1momvo4tgn7pj0y3oh41/Fig3_svg.png?rlkey=95q5swnca6eb1vg7ozhe9tlom&st=3xe8ggqj&dl=0)


The following visualizations illustrate trajectories generated by our method when the target object is partially or entirely occluded. Even under these challenging conditions, our approach accurately predicts the target object's location and successfully completes the tasks.

|*Stacking Box Occluded by Obstacle*|*Pushing Box Occluded by Obstacle*|*Lifting Box Occluded by Obstacle*|
|:-:|:-:|:-:|
|![jaco-stack-box-obs](http://dl.dropbox.com/s/k9w5kok1mk9x43a/jaco-stack-box-under-obstacle_v1.gif "jaco-stack-box-under-obstacle")|![jaco-push-box-obs](http://dl.dropbox.com/s/jy2f01w7zhcytaj/jaco-push-box-under-obstacle_v2.gif "jaco-move-box-under-obstacle")|![jaco-lift-box-obs](http://dl.dropbox.com/s/g9v84b8awc2maxv/jaco-lift-box-under-obstacle_v1.gif "jaco-lift-box-under-obstacle")|



## Instructions

**Option 1: Using a Docker Image**

The simplest way to install all required dependencies is to use a Docker image. You can pull it with the following command:

    docker pull samyeulnoh/mfd-rn:latest

**Option 2: Creating a Virtual Environment and Installing Packages**

If you prefer not to use Docker, you can create a vitual environment and install the required packages as follows:

    sudo apt update
    sudo apt install libosmesa6-dev libegl1-mesa libgl1-mesa-glx libglfw3
    conda env create -f conda_env.yml
    conda activate mfd-rn
    pip3 install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116

**Training an RL agent**

Once the environment is set up, you can train an RL agent on the *Stacking Box Occluded by Obstacle* task by running:

    python train.py task=jaco_stack_box_obstacle



## License

This repository is licensed under the MIT license. MuJoCo and DeepMind Control Suite are licensed under the Apache 2.0 license.
